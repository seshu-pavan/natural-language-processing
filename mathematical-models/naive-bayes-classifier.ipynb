{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bb645f",
   "metadata": {},
   "source": [
    "## Naive bayes classifier for sentiment analysis\n",
    "\n",
    "Naive bayes is a probabilistic Bayesian model which calcultes the predictions based on probabilities although naive bayes is not extensively used in practise the ideas and initiation is used throughout Natural Language Processing(NLP).\n",
    "\n",
    "In this notebook, we will look into building a quick baseline sentiment analysis model positive vs negative using naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7c9e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "import nltk\n",
    "import re \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from os import getcwd\n",
    "\n",
    "nltk.download('twitter_samples', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08256b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de558bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the positive tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "#creating training and test sets\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "#creating the labels\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18248047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\" The function cleans and retuens a processed tweet\"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    clean_tweets = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and word not in string.punctuation):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            clean_tweets.append(stem_word)\n",
    "    return clean_tweets\n",
    "\n",
    "def lookup(freqs, word, label):\n",
    "    \"\"\"This functions looksup the number of times a word occurs\"\"\"\n",
    "    n = 0\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n\n",
    "\n",
    "def count_tweets(result, tweets, ys):\n",
    "    \"\"\"This functions counts the tweets based on sentiment\"\"\"\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf9bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 9162\n"
     ]
    }
   ],
   "source": [
    "freqs = count_tweets({}, train_x, train_y)\n",
    "\n",
    "def naive_bayes(freqs, train_x, train_y):\n",
    "    loglikeihood = {}\n",
    "    logprior = 0\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "    \n",
    "    N_pos = 0\n",
    "    N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair]\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "            \n",
    "    D = len(train_y)\n",
    "    D_pos = np.sum(train_y)\n",
    "    D_neg = D - D_pos\n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "    \n",
    "    for word in vocab:\n",
    "        freq_pos = lookup(freqs, word, 1)\n",
    "        freq_neg = lookup(freqs, word, 0)\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "        loglikeihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "    return logprior, loglikeihood\n",
    "\n",
    "logprior, loglikelihood = naive_bayes(freqs, train_x, train_y)\n",
    "print(logprior, len(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb53bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1.5105245506722396\n"
     ]
    }
   ],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    word_list = process_tweet(tweet)\n",
    "    p = 0\n",
    "    p += logprior\n",
    "    for word in word_list:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    return p\n",
    "\n",
    "my_tweet = \"I'm Happy today!!\"\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print(f\"The expected output is {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e969cdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 5, 'negative': 100, 'ratio': 0.0594059405940594}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood, naive_bayes_predict = naive_bayes_predict):\n",
    "    accuracy = 0\n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            y_hat_i = 0\n",
    "            \n",
    "    error = np.mean(np.absolute(y_hats-test_y))\n",
    "    accuracy = 1 - error\n",
    "    return accuracy\n",
    "\n",
    "def get_ratio(freqs, word):\n",
    "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
    "    pos_neg_ratio['positive'] = lookup(freqs,word,1)\n",
    "    pos_neg_ratio['negative'] = lookup(freqs,word,0)\n",
    "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive'] + 1)/(pos_neg_ratio['negative'] + 1)\n",
    "    return pos_neg_ratio\n",
    "\n",
    "get_ratio(freqs, 'sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d401c50",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcad9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classify(tweet, logprior, loglikelihood, threshold=0.5):\n",
    "    word_list = process_tweet(tweet)\n",
    "    p = logprior\n",
    "    for word in word_list:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    sentiment = 1 if p > threshold else 0\n",
    "    return f\"Predicted Sentiment: {'Positive' if sentiment == 1 else 'Negative'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c91a274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'Im happy as its my birthday'\n",
    "\n",
    "p = naive_bayes_classify(my_tweet, logprior, loglikelihood)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98598a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'Today is a sad day'\n",
    "\n",
    "p = naive_bayes_classify(my_tweet, logprior, loglikelihood)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb5d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
